# CorAI - Pr√©diction de Maladies Cardiaques par Machine Learning

**Auteur :** Jeathusan 
**Date :** 04 D√©cembre 2025
**GitHub :** [github.com/Jeathu/corai](https://github.com/Jeathu/corai)

---

## 1. Introduction

### Contexte

Les maladies cardiovasculaires sont la **premi√®re cause de mortalit√© mondiale** (17.9 millions de d√©c√®s/an). Le diagnostic repose sur des examens co√ªteux et l'expertise de sp√©cialistes peu disponibles.

### Objectif

D√©velopper un syst√®me ML de pr√©diction du risque cardiaque √† partir de 16 variables cliniques simples.

| Objectif | Cible | R√©sultat |
|----------|-------|----------|
| Accuracy | ‚â• 85% | ‚úÖ **99%** |
| F1-Score | ‚â• 0.85 | ‚úÖ **0.99** |
| Architecture extensible | Factory Pattern | ‚úÖ |

---

## 2. Les Donn√©es

**Fichier :** `data/raw/heart_disease_dataset.csv`  
**Taille :** 1000 patients √ó 17 colonnes

### Variables

| Type | Nombre | Exemples |
|------|--------|----------|
| **Num√©riques** | 7 | Age, Cholesterol, Blood Pressure, Heart Rate |
| **Cat√©gorielles** | 9 | Gender, Smoking, Diabetes, Chest Pain Type |
| **Target** | 1 | Heart Disease (0/1) |

### √âquilibre des Classes

```
Sains   : 608 (60.8%)
Malades : 392 (39.2%)
Ratio 1.55:1 ‚Üí √âquilibr√© üòÅ (pas besoin de SMOTE)
```


---

## 3. Pr√©traitement

### Pourquoi c'est crucial ?

| Mod√®le | Sans pr√©traitement | Avec pr√©traitement |
|--------|-------------------|-------------------|
| SVM | 65% | **85%** (+20%) |
| Logistic Regression | 78% | **86%** (+8%) |

### Architecture en 3 Modules


![Architecture du preprocessing](../corai/corai/preprocessing/doc/image/preprocess.png)


**Int√©r√™ts :**
- **Maintenabilit√©** : modifier une √©tape sans toucher aux autres
- **Testabilit√©** : tests unitaires par module
- **Scalabilit√©** : ajout facile de nouvelles transformations

### Transformations Appliqu√©es

#### Encodage : Transformation des variables cat√©gorielles en variables num√©riques (One-Hot Encoding scikit-learn)

```python
# Avec encodage One-Hot : Male‚Üí[1,0], Female‚Üí[0,1]
```


#### Mise √† l'√©chelle : Standardisation des caract√©ristiques num√©riques

```
X_normalis√© = (X - moyenne) / √©cart-type
```

| Variable | Avant | Apr√®s |
|----------|-------|-------|
| Age = 45 | 45 | -0.85 |
| Cholesterol = 200 | 200 | -0.71 |

### Data Leakage - Pr√©caution Critique

```python
# ‚ùå ERREUR : scaler.fit(X_complet)
# ‚úÖ CORRECT : scaler.fit(X_train) puis transform(X_test)
```

---

## 4. Mod√®les

![Architecture du mod√®le](../corai/corai/preprocessing/doc/image/models_sc.png)

### Strat√©gie Multi-Mod√®les

| Mod√®le | Type | Force |
|--------|------|-------|
| Logistic Regression | Lin√©aire | Interpr√©table, baseline |
| Random Forest | Bagging | Robuste, feature importance |
| Gradient Boosting | Boosting | Tr√®s performant |
| SVM | Kernel | Haute dimension |

### Random Forest - Choix Principal

**Pourquoi ?**
1. Vote de 100 arbres ‚Üí robuste
2. Feature importance ‚Üí interpr√©table
3. G√®re les interactions non-lin√©aires

### Validation Crois√©e Stratifi√©e 5-Fold

```
Fold 1: [VAL][TRAIN][TRAIN][TRAIN][TRAIN]
Fold 2: [TRAIN][VAL][TRAIN][TRAIN][TRAIN]
...
‚Üí 5 √©valuations, score = moyenne
```

Pr√©serve le ratio 60/40 dans chaque fold.

---

## 5. R√©sultats

### Performances

| Mod√®le | Accuracy | F1-Score | ROC AUC |
|--------|----------|----------|---------|
| Logistic Regression | 86% | 0.859 | 0.951 |
| SVM | 85% | 0.850 | 0.920 |
| **Random Forest** | **99%** | **0.990** | **1.000** |
| Gradient Boosting | 100% | 1.000 | 1.000 |

### Tableau comparatif des mod√®les test√©s :
![Architecture du mod√®le](../corai/corai/preprocessing/doc/image/tableau_comp.png)

### Matrice de Confusion (Random Forest)

```
              Pr√©dit 0  Pr√©dit 1
R√©el 0          122        0
R√©el 1            2       76

Erreurs : 2/200 (1%)
```

### Features Importantes

```
1. Cholesterol      (0.18)
2. Age              (0.15)
3. Blood Pressure   (0.13)
4. Exercise Hours   (0.11)
5. Chest Pain Type  (0.09)
```

‚Üí Conforme √† la litt√©rature m√©dicale ‚úì

### Pourquoi Random Forest et pas Gradient Boosting (100%) ?

- 100% sur 1000 √©chantillons = suspect (surapprentissage)
- Random Forest : meilleure g√©n√©ralisation

---

## 6. Architecture de fichier source 

```
corai/
‚îú‚îÄ‚îÄ preprocessing/
‚îÇ   ‚îú‚îÄ‚îÄ data_loader.py           # Chargement
‚îÇ   ‚îú‚îÄ‚îÄ feature_transformer.py   # Transformation
‚îÇ   ‚îî‚îÄ‚îÄ preprocessing_pipeline.py # Orchestration
‚îÇ
‚îú‚îÄ‚îÄ modeling/
‚îÇ   ‚îú‚îÄ‚îÄ abstraite_base_model.py  # Classe abstraite
‚îÇ   ‚îú‚îÄ‚îÄ model_factory.py         # Factory Pattern
‚îÇ   ‚îú‚îÄ‚îÄ train.py / predict.py / evaluate.py
‚îÇ   ‚îî‚îÄ‚îÄ classifiers/             # RF, GB, LR, SVM
‚îÇ
‚îú‚îÄ‚îÄ analytics/                   # EDA, visualisations
‚îú‚îÄ‚îÄ pipeline_complete.py         # Pipeline end-to-end
‚îî‚îÄ‚îÄ config.py                    # Configuration centralis√©e
```

### Factory Pattern

```python
model = ModelFactory.create("random_forest", n_estimators=200)
model = ModelFactory.create("gradient_boosting")
# ‚Üí Extensible : ajouter XGBoost = 1 fichier + 1 ligne
```

---

## 7. Utilisation

### Option 1 : Pipeline Complet (Recommand√©)

```bash
# Installation
git clone https://github.com/Jeathu/corai.git
cd corai && pip install -r requirements.txt

# Pr√©traitement des donn√©es
python -m corai.preprocessing.preprocessing_pipeline
# Input: data/raw/heart_disease_dataset.csv
# Output: data/processed/processed_heart_disease_v0.csv

# Ex√©cution du pipeline complet
python -m corai.pipeline_complete
```

### Option 2 : Entra√Ænement, Pr√©diction et √âvaluation S√©par√©s

> ‚ö†Ô∏è **Pr√©requis :** Vous devez √™tre dans l'environnement virtuel (suivre les √©tapes de `instruction_conf.txt`)

#### Entra√Ænement du mod√®le

```bash
# Random Forest (d√©faut)
python -m corai.modeling.train

# Autres mod√®les disponibles
python -m corai.modeling.train --model-type gradient_boosting
python -m corai.modeling.train --model-type logistic_regression
python -m corai.modeling.train --model-type svm
```

- **Input :** `data/processed/processed_heart_disease_v0.csv`
- **Output :** `models/heart_disease_model.pkl`

#### Pr√©diction

```bash
python -m corai.modeling.predict
```

- **Input :** `data/processed/test_features.csv`, `models/heart_disease_model.pkl`
- **Output :** `models/predictions/test_predictions.csv`

> ‚ö†Ô∏è **Note :** Cette commande n√©cessite que vous ayez d'abord ex√©cut√© le pipeline complet.

#### √âvaluation

```bash
python -m corai.modeling.evaluate
```

- **Input :** `data/processed/test_predictions.csv`, `data/processed/test_labels.csv`
- **Output :** `reports/evaluation_metrics.json`

---

## 8. Conclusion

### R√©alisations

| Objectif | Statut |
|----------|--------|
| Accuracy ‚â• 85% | ‚úÖ 99% |
| Architecture extensible | ‚úÖ Factory + Pipeline |
| Validation robuste | ‚úÖ CV 5-fold |

### Points Forts

- **99% accuracy** avec 2 erreurs sur 200 patients
- **Architecture modulaire** (responsabilit√© unique, design patterns)
- **Feature importance** coh√©rente avec la m√©decine

### Am√©liorations Futures

- Ajouter XGBoost, SHAP
- API REST (FastAPI)
- Docker

---

**04 D√©cembre 2025 - Module d'Apprentissage Artificiel**