# CorAI - PrÃ©diction de Maladies Cardiaques par Machine Learning

**Auteur :** Jeathusan et Merouane  
**Date :** 04 DÃ©cembre 2025
<hr/>

**GitHub :** [github.com/Jeathu/corai](https://github.com/Jeathu/corai)   
**Source :** [Kaggle](https://www.kaggle.com/datasets/rashadrmammadov/heart-disease-prediction)   
**PrÃ©sentation(en cours de progression) :** [Canva](https://www.canva.com/design/DAG6dMip9c4/Zi8ENREUPbaIjSDzmKoq-A/view?utm_content=DAG6dMip9c4&utm_campaign=designshare&utm_medium=link2&utm_source=uniquelinks&utlId=he0c4e8db3f)

---

## *1. Introduction*

### - Contexte

Les maladies cardiovasculaires sont la **premiÃ¨re cause de mortalitÃ© mondiale** (17.9 millions de dÃ©cÃ¨s/an). Le diagnostic repose sur des examens coÃ»teux et l'expertise de spÃ©cialistes peu disponibles.

### - Objectif

DÃ©velopper un systÃ¨me ML de prÃ©diction du risque cardiaque Ã  partir de 16 variables cliniques simples.

| Objectif | Cible | RÃ©sultat |
|----------|-------|----------|
| Accuracy | â‰¥ 85% | âœ… **99%** |
| F1-Score | â‰¥ 0.85 | âœ… **0.99** |
| Architecture extensible | Factory Pattern | âœ… |

---
<br>

## *2. Les DonnÃ©es*

**Fichier :** `data/raw/heart_disease_dataset.csv`  
**Taille :** 1000 patients Ã— 17 colonnes

### Variables

| Type | Nombre | Exemples |
|------|--------|----------|
| **NumÃ©riques** | 7 | Age, Cholesterol, Blood Pressure, Heart Rate |
| **CatÃ©gorielles** | 9 | Gender, Smoking, Diabetes, Chest Pain Type |
| **Target** | 1 | Heart Disease (0/1) |

### Ã‰quilibre des Classes

```
Sains   : 608 (60.8%)
Malades : 392 (39.2%)
Ratio 1.55:1 â†’ Ã‰quilibrÃ© ğŸ˜ (pas besoin de SMOTE)
```
![Comparative de Ã©quilibrage](/images/output.png)


__*- Recherche effectuÃ©e sur le rÃ©Ã©quilibrage de dataset*__

![rÃ©Ã©quilibrage](/images/equilibrage.png)

* Mais dans notre cas, le dataset est Ã©quilibrÃ© donc pas besoin de rÃ©Ã©quilibrage.

#### __*- Recherche effectuÃ©e*__
* **SMOTE** (__*Over - sampling Technique*__) est une technique pour Ã©quilibrer un dataset en crÃ©ant de nouvelles donnÃ©es synthÃ©tiques pour la classe minoritaire.

![smote](/images/SMOTE-points-for.png)


---
<br>

## *3. PrÃ©traitement*
### Pourquoi c'est crucial ?

| ModÃ¨le | Sans prÃ©traitement | Avec prÃ©traitement |
|--------|-------------------|-------------------|
| SVM | 65% | **85%** (+20%) |
| Logistic Regression | 78% | **86%** (+8%) |

### Architecture en 3 Modules

![Architecture du preprocessing](/images/preprocess.png)




__*- Mais dans notre cas, le dataset est Ã©quilibrÃ© donc pas besoin de rÃ©Ã©quilibrage.*__

**IntÃ©rÃªts :**
- **MaintenabilitÃ©** : modifier une Ã©tape sans toucher aux autres
- **TestabilitÃ©** : tests unitaires par module
- **ScalabilitÃ©** : ajout facile de nouvelles transformations

### __*- Transformations AppliquÃ©es*__

#### Encodage : Transformation des variables catÃ©gorielles en variables numÃ©riques (One-Hot Encoding scikit-learn)

```python
# Avec encodage One-Hot : Maleâ†’[1,0], Femaleâ†’[0,1]
```


#### Mise Ã  l'Ã©chelle : Standardisation des caractÃ©ristiques numÃ©riques

```
X_normalisÃ© = (X - moyenne) / Ã©cart-type
```

| Variable | Avant | AprÃ¨s |
|----------|-------|-------|
| Age = 45 | 45 | -0.85 |
| Cholesterol = 200 | 200 | -0.71 |

### Data Leakage - PrÃ©caution Critique

```python
# âŒ ERREUR : scaler.fit(X_complet)
# âœ… CORRECT : scaler.fit(X_train) puis transform(X_test)
```

---

<br>

## *4. ModÃ¨les*

![Architecture du modÃ¨le](/images/models_sc.png)

### StratÃ©gie Multi-ModÃ¨les

| ModÃ¨le | Type | Force |
|--------|------|-------|
| Logistic Regression | LinÃ©aire | InterprÃ©table, baseline |
| Random Forest | Bagging | Robuste, feature importance |
| Gradient Boosting | Boosting | TrÃ¨s performant |
| SVM | Kernel | Haute dimension |

### Random Forest - Choix Principal

**Pourquoi ?**
1. Vote de 100 arbres â†’ robuste
2. Feature importance â†’ interprÃ©table
3. GÃ¨re les interactions non-linÃ©aires


<br>

## *5. RÃ©sultats*

### Performances

| ModÃ¨le | Accuracy | F1-Score | ROC AUC |
|--------|----------|----------|---------|
| Logistic Regression | 86% | 0.859 | 0.951 |
| SVM | 85% | 0.850 | 0.920 |
| **Random Forest** | **99%** | **0.990** | **1.000** |
| Gradient Boosting | 100% | 1.000 | 1.000 |

### Tableau comparatif des modÃ¨les testÃ©s :
![Tableau comparatif](/images/tableau_comp.png)

### Matrice de Confusion (Random Forest)

```
              PrÃ©dit 0  PrÃ©dit 1
RÃ©el 0          122        0
RÃ©el 1            2       76

Erreurs : 2/200 (1%)
```

### Features Importantes

```
1. Cholesterol      (0.18)
2. Age              (0.15)
3. Blood Pressure   (0.13)
4. Exercise Hours   (0.11)
5. Chest Pain Type  (0.09)
```

â†’ Conforme Ã  la littÃ©rature mÃ©dicale âœ“

### Pourquoi Random Forest et pas Gradient Boosting (100%) ?

- 100% sur 1000 Ã©chantillons = suspect (surapprentissage)
- Random Forest : meilleure gÃ©nÃ©ralisation

---

<br>

## *6. Architecture de fichier source*

```
corai/
â”œâ”€â”€ preprocessing/
â”‚   â”œâ”€â”€ data_loader.py           # Chargement
â”‚   â”œâ”€â”€ feature_transformer.py   # Transformation
â”‚   â””â”€â”€ preprocessing_pipeline.py # Orchestration
â”‚
â”œâ”€â”€ modeling/
â”‚   â”œâ”€â”€ abstraite_base_model.py  # Classe abstraite
â”‚   â”œâ”€â”€ model_factory.py         # Factory Pattern
â”‚   â”œâ”€â”€ train.py / predict.py / evaluate.py
â”‚   â””â”€â”€ classifiers/             # RF, GB, LR, SVM
â”‚
â”œâ”€â”€ analytics/                   # EDA, visualisations
â”œâ”€â”€ pipeline_complete.py         # Pipeline end-to-end
â””â”€â”€ config.py                    # Configuration centralisÃ©e
```

### Factory Pattern

```python
model = ModelFactory.create("random_forest", n_estimators=200)
model = ModelFactory.create("gradient_boosting")
# â†’ Extensible : ajouter XGBoost = 1 fichier + 1 ligne
```

---

<br>

## *7. Utilisation*

### Option 1 : Pipeline Complet (RecommandÃ©)

```bash
# Installation
git clone https://github.com/Jeathu/corai.git
cd corai && pip install -r requirements.txt

# PrÃ©traitement des donnÃ©es
python -m corai.preprocessing.preprocessing_pipeline
# Input: data/raw/heart_disease_dataset.csv
# Output: data/processed/processed_heart_disease_v0.csv

# ExÃ©cution du pipeline complet
python -m corai.pipeline_complete
```

### Option 2 : EntraÃ®nement, PrÃ©diction et Ã‰valuation SÃ©parÃ©s

> âš ï¸ **PrÃ©requis :** Vous devez Ãªtre dans l'environnement virtuel (suivre les Ã©tapes de `instruction_conf.txt`)

#### EntraÃ®nement du modÃ¨le

```bash
# Random Forest (dÃ©faut)
python -m corai.modeling.train

# Autres modÃ¨les disponibles
python -m corai.modeling.train --model-type gradient_boosting
python -m corai.modeling.train --model-type logistic_regression
python -m corai.modeling.train --model-type svm
```

- **Input :** `data/processed/processed_heart_disease_v0.csv`
- **Output :** `models/heart_disease_model.pkl`

#### PrÃ©diction

```bash
python -m corai.modeling.predict
```

- **Input :** `data/processed/test_features.csv`, `models/heart_disease_model.pkl`
- **Output :** `models/predictions/test_predictions.csv`

> âš ï¸ **Note :** Cette commande nÃ©cessite que vous ayez d'abord exÃ©cutÃ© le pipeline complet.

#### Ã‰valuation

```bash
python -m corai.modeling.evaluate
```

- **Input :** `data/processed/test_predictions.csv`, `data/processed/test_labels.csv`
- **Output :** `reports/evaluation_metrics.json`

---

<br>

## *8. Conclusion*

### RÃ©alisations

| Objectif | Statut |
|----------|--------|
| Accuracy â‰¥ 85% | âœ… 99% |
| Architecture extensible | âœ… Factory + Pipeline |

### Points Forts

- **99% accuracy** avec 2 erreurs sur 200 patients
- **Architecture modulaire** (responsabilitÃ© unique, design patterns)
- **Feature importance** cohÃ©rente avec la mÃ©decine

### AmÃ©liorations Futures

- Ajouter XGBoost, SHAP
- API REST (FastAPI)
- Docker

---

<br>

## *9. Organisation du projet du CorAi*

```
corai/
â”œâ”€â”€ corai/                          # package source
â”‚   â”œâ”€â”€ analytics/
â”‚   â”‚   â”œâ”€â”€ visualizations/         # visualisations des donnÃ©es
â”‚   â”‚   â”œâ”€â”€ eda.py                  # analyse exploratoire des donnÃ©es
â”‚   â”‚   â””â”€â”€ synthese_variables.py   # synthÃ¨se des variables
â”‚   â”œâ”€â”€ preprocessing/
â”‚   â”‚   â”œâ”€â”€ data_loader.py          # chargement et nettoyage des donnÃ©es
â”‚   â”‚   â”œâ”€â”€ feature_transformer.py  # transformations des caractÃ©ristiques
â”‚   â”‚   â””â”€â”€ preprocessing_pipeline.py
â”‚   â”œâ”€â”€ modeling/
â”‚   â”‚   â”œâ”€â”€ abstraite_base_model.py # classe abstraite
â”‚   â”‚   â”œâ”€â”€ model_factory.py        # factory pattern
â”‚   â”‚   â”œâ”€â”€ train.py
â”‚   â”‚   â”œâ”€â”€ predict.py
â”‚   â”‚   â”œâ”€â”€ evaluate.py
â”‚   â”‚   â””â”€â”€ classifiers/            # RF, GB, LR, SVM
â”‚   â””â”€â”€ __init__.py
â”œâ”€â”€ analytics/                      # EDA et visualisations (niveau projet)
â”œâ”€â”€ pipeline_complete.py            # pipeline end-to-end
â”œâ”€â”€ config.py                       # configuration (hyperparamÃ¨tres, chemins)
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ external/                   # donnÃ©es tierces
â”‚   â”œâ”€â”€ interim/                    # donnÃ©es intermÃ©diaires
â”‚   â”œâ”€â”€ processed/                  # jeux finaux pour modÃ©lisation
â”‚   â””â”€â”€ raw/                        # donnÃ©es brutes immuables
â”œâ”€â”€ docs/                           # documentation
â”œâ”€â”€ models/                         # modÃ¨les entraÃ®nÃ©s et sorties
â”‚   â””â”€â”€ predictions/                # fichiers de prÃ©diction (CSV)
â”œâ”€â”€ notebooks/                      # notebooks d'EDA et notes
â”œâ”€â”€ reports/                        # rapports mÃ©triques (JSON)
â”‚   â””â”€â”€ figures/                    # figures et graphiques
â”œâ”€â”€ tests/                          # tests unitaires et E2E
â”œâ”€â”€ venv/                           # environnement virtuel
â”œâ”€â”€ instruction_conf.txt            # guide de configuration du venv
â”œâ”€â”€ README.md                       # documentation principale
â””â”€â”€ requirements.txt                # dÃ©pendances
```


**04 DÃ©cembre 2025 - Module d'Apprentissage Artificiel**