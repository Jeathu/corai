# CorAI - PrÃ©diction de Maladies Cardiaques par Machine Learning

**Auteur :** Jeathusan et Merouane  
**Date :** 04 DÃ©cembre 2025
<hr/>

**GitHub :** [github.com/Jeathu/corai](https://github.com/Jeathu/corai)   
**Source dataset :** [Kaggle](https://www.kaggle.com/datasets/rashadrmammadov/heart-disease-prediction)   
**PrÃ©sentation(en cours de progression) :** [Canva](https://www.canva.com/design/DAG6dMip9c4/Zi8ENREUPbaIjSDzmKoq-A/view?utm_content=DAG6dMip9c4&utm_campaign=designshare&utm_medium=link2&utm_source=uniquelinks&utlId=he0c4e8db3f)

---

## *1. Introduction*

### - Contexte

Les maladies cardiovasculaires sont la **premiÃ¨re cause de mortalitÃ© mondiale** (17.9 millions de dÃ©cÃ¨s/an). Le diagnostic repose sur des examens coÃ»teux et l'expertise de spÃ©cialistes peu disponibles.

### - Objectif

DÃ©velopper un systÃ¨me ML de prÃ©diction du risque cardiaque Ã  partir de 16 variables cliniques simples.

| Objectif | Cible | RÃ©sultat |
|----------|-------|----------|
| Accuracy | â‰¥ 85% |  **99%** |
| F1-Score | â‰¥ 0.85 | **0.99** |
| Architecture extensible | Factory Pattern |  |

---
<br>

## *2. Les DonnÃ©es*

**Fichier :** `data/raw/heart_disease_dataset.csv`  
**Taille :** 1000 patients Ã— 17 colonnes

### Variables

| Type | Nombre | Exemples |
|------|--------|----------|
| **NumÃ©riques** | 7 | Age, Cholesterol, Blood Pressure, Heart Rate |
| **CatÃ©gorielles** | 9 | Gender, Smoking, Diabetes, Chest Pain Type |
| **Target** | 1 | Heart Disease (0/1) |

### Ã‰quilibre des Classes

```
Sains   : 608 (60.8%)
Malades : 392 (39.2%)
Ratio 1.55:1 â†’ Ã‰quilibrÃ© ğŸ˜ (pas besoin de SMOTE)
```
![Comparative de Ã©quilibrage](/images/output.png)


__*- Recherche effectuÃ©e sur le rÃ©Ã©quilibrage de dataset*__

![rÃ©Ã©quilibrage](/images/equilibrage.png)

* Mais dans notre cas, le dataset est Ã©quilibrÃ© donc pas besoin de rÃ©Ã©quilibrage.

#### __*- Recherche effectuÃ©e*__
* **SMOTE** (__*Over - sampling Technique*__) est une technique pour Ã©quilibrer un dataset en crÃ©ant de nouvelles donnÃ©es synthÃ©tiques pour la classe minoritaire.

![smote](/images/SMOTE-points-for.png)


---
<br>

## *3. PrÃ©traitement*
### Pourquoi c'est crucial ?

**le prÃ©traitement amÃ©liore la qualitÃ© des donnÃ©es brutes, ce qui est essentiel pour la performance des modÃ¨les ML.**

<br>

* __**Par exemple :**__

| ModÃ¨le | Sans prÃ©traitement | Avec prÃ©traitement |
|--------|-------------------|-------------------|
| SVM | 65% | **85%** (+20%) |
| Logistic Regression | 78% | **86%** (+8%) |

<br>

### Architecture en 3 Modules

![Architecture du preprocessing](/images/preprocess.png)


<br>

* __*Architecture en trois modules :*__


#### `Data Loader :`
 * Charge les donnÃ©es brutes, gÃ¨re les valeurs manquantes et sÃ©pare la variable cible (Y) des features (X).On garde uniquement le target.


#### `Feature Transformer :`
 * Applique les transformations uniquement sur les features (X), telles que lâ€™encodage des variables catÃ©gorielles et la normalisation des variables numÃ©riques.


#### `Preprocessing Pipeline`
 * Orchestre le prÃ©traitement final en utilisant les features transformÃ©es (provenant du Feature Transformer) et la cible Y (provenant du Data Loader).GrÃ¢ce Ã  la mÃ©thode fit_transform, il produit un dataset prÃ©traitÃ© et structurÃ©, ce qui justifie la sÃ©paration en deux modules distincts.


* __*vous pouvez consulter le data prÃ©traitÃ© dans le dossier `data/processed/` sous le nom `processed_heart_disease_v0.csv`.*__

<br>

**IntÃ©rÃªts :**
- **MaintenabilitÃ©** : modifier une Ã©tape sans toucher aux autres
- **TestabilitÃ©** : tests unitaires par module
- **ScalabilitÃ©** : ajout facile de nouvelles transformations


<br>

### __*- Transformations AppliquÃ©es*__

#### Encodage : Transformation des variables catÃ©gorielles en variables numÃ©riques (One-Hot Encoding scikit-learn)

```python
# Avec encodage One-Hot : Maleâ†’[1,0], Femaleâ†’[0,1]
```

![Architecture du preprocessing](/images/onehotencodepng.png)


<br>


#### Mise Ã  l'Ã©chelle : Standardisation des caractÃ©ristiques numÃ©riques (StandardScaler scikit-learn)

```
X_normalisÃ© = (X - moyenne) / Ã©cart-type
```

| Variable | Avant | AprÃ¨s |
|----------|-------|-------|
| Age = 45 | 45 | -0.85 |
| Cholesterol = 200 | 200 | -0.71 |

<br>


![Architecture du preprocessing](/images/stand.png)

---

<br>
<br>

## *4. ModÃ¨les*

![Architecture du modÃ¨le](/images/models_sc.png)

### StratÃ©gie Multi-ModÃ¨les

| ModÃ¨le | Type | Force |
|--------|------|-------|
| Logistic Regression | LinÃ©aire | InterprÃ©table, baseline |
| Random Forest | Bagging | Robuste, feature importance |
| Gradient Boosting | Boosting | TrÃ¨s performant |
| SVM | Kernel | Haute dimension |

### Random Forest - Choix Principal

**Pourquoi ?**
1. Vote de 100 arbres â†’ robuste
2. Feature importance â†’ interprÃ©table
3. GÃ¨re les interactions non-linÃ©aires


<br>

## *5. RÃ©sultats*

### Performances

| ModÃ¨le | Accuracy | F1-Score | ROC AUC |
|--------|----------|----------|---------|
| Logistic Regression | 86% | 0.859 | 0.951 |
| SVM | 85% | 0.850 | 0.920 |
| **Random Forest** | **99%** | **0.990** | **1.000** |
| **Gradient Boosting** | **100%** | **1.000** | **1.000** |

<br>

### Une exemple de  aperÃ§u des rÃ©sultats
* __*( 0 = Pas de maladie cardiaque, 1 = Maladie cardiaque )*__

<br>

![RÃ©sultats](/images/prdi.png)

<hr/>

### Tableau comparatif des modÃ¨les testÃ©s :
![Tableau comparatif](/images/metrique_md.png)

### Matrice de Confusion (Random Forest)

```
              PrÃ©dit 0  PrÃ©dit 1
RÃ©el 0          122        0
RÃ©el 1            2       76

Erreurs : 2/200 (1%)

```

### Cross-Validation (Random Forest)

* C'est quoi la cross-validation ?
   - MÃ©thode d'Ã©valuation des modÃ¨les qui divise les donnÃ©es en plusieurs parties (folds).Chaque partie sert tour Ã  tour de jeu de test, les autres servant Ã  l'entraÃ®nement.Cela donne une estimation plus fiable des performances.

<br>

![Tableau comparatif](/images/crosse.png)

* `Moyenne = (Somme des scores) Ã· (Nombre de folds)`

```
Fold 1: 100%  (1)
Fold 2: 100%  (1)
Fold 3: 100%  (1)
Fold 4: 100%  (1)
Fold 5: 99%   (0.099375)

Calcule : 1 + 1 + 1 + 1+ 0.99 = 4.99 Ã· 5 = 0.998

Moyenne : 99.8%
```

<br>

---

<br>

## *6. Architecture de fichier source*

```
corai/
â”œâ”€â”€ preprocessing/
â”‚   â”œâ”€â”€ data_loader.py           # Chargement
â”‚   â”œâ”€â”€ feature_transformer.py   # Transformation
â”‚   â””â”€â”€ preprocessing_pipeline.py # Orchestration
â”‚
â”œâ”€â”€ modeling/
â”‚   â”œâ”€â”€ abstraite_base_model.py  # Classe abstraite
â”‚   â”œâ”€â”€ model_factory.py         # Factory Pattern
â”‚   â”œâ”€â”€ train.py / predict.py / evaluate.py
â”‚   â””â”€â”€ classifiers/             # RF, GB, LR, SVM
â”‚
â”œâ”€â”€ analytics/                   # EDA, visualisations
â”œâ”€â”€ pipeline_complete.py         # Pipeline end-to-end
â””â”€â”€ config.py                    # Configuration centralisÃ©e
```

### Factory Pattern

```python
model = ModelFactory.create("random_forest", n_estimators=200)
model = ModelFactory.create("gradient_boosting")
# â†’ Extensible : ajouter XGBoost = 1 fichier + 1 ligne
```

---

<br>


## *7. Utilisation*

### Pour prÃ©traitemet des donnÃ©es ( si vous voulez juste prÃ©traiter )
* les donnÃ©es sont dÃ©ja prÃ©traitÃ©es dans le dossier `data/processed/`   
   donc cette Ã©tape est optionnelle.

```bash
# PrÃ©traitement des donnÃ©es
python -m corai.preprocessing.preprocessing_pipeline

# Input: data/raw/heart_disease_dataset.csv
# Output: data/processed/processed_heart_disease_v0.csv
```


### Option 1 : Pipeline Complet (RecommandÃ©)

```bash
# Installation
git clone https://github.com/Jeathu/corai.git
cd corai && pip install -r requirements.txt



# ğŸ˜… ExÃ©cution en une commande du pipeline complet
python -m corai.pipeline_complete
```

### Option 2 : EntraÃ®nement, PrÃ©diction et Ã‰valuation SÃ©parÃ©s

> âš ï¸ **PrÃ©requis :** Vous devez Ãªtre dans l'environnement virtuel (suivre les Ã©tapes de `instruction_conf.txt`)

#### EntraÃ®nement du modÃ¨le

```bash

# Random Forest (dÃ©faut)
python -m corai.modeling.train

# Autres modÃ¨les disponibles
python -m corai.modeling.train --model-type gradient_boosting
python -m corai.modeling.train --model-type logistic_regression
python -m corai.modeling.train --model-type svm
```

- **Input :** `data/processed/processed_heart_disease_v0.csv`
- **Output :** `models/heart_disease_model.pkl`

#### PrÃ©diction

```bash
python -m corai.modeling.predict
```

- **Input :** `data/processed/test_features.csv`, `models/heart_disease_model.pkl`
- **Output :** `models/predictions/test_predictions.csv`

> âš ï¸ **Note :** Cette commande nÃ©cessite que vous ayez d'abord exÃ©cutÃ© le pipeline complet.

#### Ã‰valuation

```bash
python -m corai.modeling.evaluate
```

- **Input :** `data/processed/test_predictions.csv`, `data/processed/test_labels.csv`
- **Output :** `reports/evaluation_metrics.json`

---

<br>

## *8. Conclusion*

### RÃ©alisations

| Objectif | Statut |
|----------|--------|
| Accuracy â‰¥ 85% | 99% |
| Architecture extensible | Factory + Pipeline |

les rÃ©alisations clÃ©s incluent :
- Un pipeline de prÃ©traitement modulaire
- Une architecture de modÃ©lisation extensible
- Des performances exceptionnelles (99% accuracy)
- Des indicateurs de performance cohÃ©rents avec la mÃ©decine


### Points Forts

- **99% accuracy** avec 2 erreurs sur 200 patients
- **Architecture modulaire** (responsabilitÃ© unique, design patterns)
- **Feature importance** cohÃ©rente avec la mÃ©decine

### AmÃ©liorations Futures

- Ajouter XGBoost, SHAP
- API REST (FastAPI)
- Docker
- CrÃ©ation d'une interface utilisateur pour tester le modÃ¨le facilement

---

<br>

## *9. Organisation du projet du CorAi*

```
corai/
â”œâ”€â”€ corai/                          # package source
â”‚   â”œâ”€â”€ analytics/
â”‚   â”‚   â”œâ”€â”€ visualizations/         # visualisations des donnÃ©es
â”‚   â”‚   â”œâ”€â”€ eda.py                  # analyse exploratoire des donnÃ©es
â”‚   â”‚   â””â”€â”€ synthese_variables.py   # synthÃ¨se des variables
â”‚   â”œâ”€â”€ preprocessing/
â”‚   â”‚   â”œâ”€â”€ data_loader.py          # chargement et nettoyage des donnÃ©es
â”‚   â”‚   â”œâ”€â”€ feature_transformer.py  # transformations des caractÃ©ristiques
â”‚   â”‚   â””â”€â”€ preprocessing_pipeline.py
â”‚   â”œâ”€â”€ modeling/
â”‚   â”‚   â”œâ”€â”€ abstraite_base_model.py # classe abstraite
â”‚   â”‚   â”œâ”€â”€ model_factory.py        # factory pattern
â”‚   â”‚   â”œâ”€â”€ train.py
â”‚   â”‚   â”œâ”€â”€ predict.py
â”‚   â”‚   â”œâ”€â”€ evaluate.py
â”‚   â”‚   â””â”€â”€ classifiers/            # RF, GB, LR, SVM
â”‚   â””â”€â”€ __init__.py
â”œâ”€â”€ analytics/                      # EDA et visualisations (niveau projet)
â”œâ”€â”€ pipeline_complete.py            # pipeline end-to-end
â”œâ”€â”€ config.py                       # configuration (hyperparamÃ¨tres, chemins)
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ external/                   # donnÃ©es tierces
â”‚   â”œâ”€â”€ interim/                    # donnÃ©es intermÃ©diaires
â”‚   â”œâ”€â”€ processed/                  # jeux finaux pour modÃ©lisation
â”‚   â””â”€â”€ raw/                        # donnÃ©es brutes immuables
â”œâ”€â”€ docs/                           # documentation
â”œâ”€â”€ models/                         # modÃ¨les entraÃ®nÃ©s et sorties
â”‚   â””â”€â”€ predictions/                # fichiers de prÃ©diction (CSV)
â”œâ”€â”€ notebooks/                      # notebooks d'EDA et notes
â”œâ”€â”€ reports/                        # rapports mÃ©triques (JSON)
â”‚   â””â”€â”€ figures/                    # figures et graphiques
â”œâ”€â”€ tests/                          # tests unitaires et E2E
â”œâ”€â”€ venv/                           # environnement virtuel
â”œâ”€â”€ instruction_conf.txt            # guide de configuration du venv
â”œâ”€â”€ README.md                       # documentation principale
â””â”€â”€ requirements.txt                # dÃ©pendances
```


**04 DÃ©cembre 2025 - Module d'Apprentissage Artificiel**