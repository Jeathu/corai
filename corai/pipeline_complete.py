"""
Pipeline complet end-to-end pour le projet CorAI.
Orchestre tout le workflow: pr√©traitement ‚Üí entra√Ænement ‚Üí pr√©diction ‚Üí √©valuation.
"""

from pathlib import Path
from typing import Optional, Dict, Any
import pickle

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from loguru import logger
import typer

from corai.config import (
    RAW_DATA_DIR, PROCESSED_DATA_DIR, MODELS_DIR, REPORTS_DIR,
    DEFAULT_MODEL_TYPE, DEFAULT_TEST_SIZE, DEFAULT_RANDOM_STATE, DEFAULT_CV_FOLDS, TARGET_COLUMN
)
from corai.preprocessing.data_loader import load_data, split_features_target
from corai.preprocessing.preprocessing_pipeline import DataDiagnosticsPreprocessor
from corai.modeling.train import ModelTrainer
from corai.modeling.evaluate import ModelEvaluator

app = typer.Typer()


class CompletePipeline:
    """Pipeline complet pour le projet de pr√©diction de maladies cardiaques."""

    def __init__(
        self,
        raw_data_path: Path,
        model_type: str = None,
        test_size: float = None,
        random_state: int = None
    ):
        """
        Initialise le pipeline complet.
        
        Args:
            raw_data_path: Chemin vers les donn√©es brutes
            model_type: Type de mod√®le √† entra√Æner (None = utilise DEFAULT_MODEL_TYPE)
            test_size: Proportion des donn√©es pour le test (None = utilise DEFAULT_TEST_SIZE)
            random_state: Graine al√©atoire (None = utilise DEFAULT_RANDOM_STATE)
        """
        self.raw_data_path = raw_data_path
        self.model_type = model_type or DEFAULT_MODEL_TYPE
        self.test_size = test_size or DEFAULT_TEST_SIZE
        self.random_state = random_state or DEFAULT_RANDOM_STATE
        
        # Donn√©es
        self.df_raw: Optional[pd.DataFrame] = None
        self.df_processed: Optional[pd.DataFrame] = None
        self.X_train: Optional[pd.DataFrame] = None
        self.X_test: Optional[pd.DataFrame] = None
        self.y_train: Optional[pd.Series] = None
        self.y_test: Optional[pd.Series] = None
        
        # Mod√®le
        self.trainer: Optional[ModelTrainer] = None
        self.model = None
        
        # R√©sultats
        self.predictions: Optional[np.ndarray] = None
        self.probabilities: Optional[np.ndarray] = None
        self.metrics: Dict[str, Any] = {}

    def step1_load_and_preprocess(self) -> pd.DataFrame:
        """
        √âtape 1: Charger et pr√©traiter les donn√©es.
        
        Returns:
            DataFrame pr√©trait√©
        """
        logger.info("=" * 80)
        logger.info("√âTAPE 1: CHARGEMENT ET PR√âTRAITEMENT DES DONN√âES")
        logger.info("=" * 80)
        
        # Cr√©er le pipeline de pr√©traitement
        pipeline = DataDiagnosticsPreprocessor(target_column=TARGET_COLUMN)
        
        # Charger les donn√©es
        logger.info(f"Chargement depuis: {self.raw_data_path}")
        pipeline.load(self.raw_data_path)
        self.df_raw = pipeline.df
        logger.info(f"Donn√©es brutes charg√©es: {self.df_raw.shape}")
        
        # Supprimer les doublons
        removed = pipeline.remove_duplicates()
        logger.info(f"Doublons supprim√©s: {removed}")
        
        # Appliquer le pr√©traitement
        logger.info("Application du pr√©traitement...")
        pipeline.fit_transform_preprocessor()
        
        # R√©cup√©rer les donn√©es transform√©es
        X_transformed = pipeline.X_transformed
        y_transformed = pipeline.y_arr
        
        # Combiner en un seul DataFrame
        self.df_processed = X_transformed.copy()
        self.df_processed[TARGET_COLUMN] = y_transformed
        
        logger.success(f"Donn√©es pr√©trait√©es: {self.df_processed.shape}")
        
        # Sauvegarder les donn√©es pr√©trait√©es
        processed_path = PROCESSED_DATA_DIR / "processed_heart_disease_complete.csv"
        processed_path.parent.mkdir(parents=True, exist_ok=True)
        self.df_processed.to_csv(processed_path, index=False)
        logger.info(f"Donn√©es pr√©trait√©es sauvegard√©es: {processed_path}")
        
        return self.df_processed

    def step2_split_data(self):
        """√âtape 2: S√©parer les donn√©es en train/test."""
        logger.info("=" * 80)
        logger.info("√âTAPE 2: S√âPARATION TRAIN/TEST")
        logger.info("=" * 80)
        
        # S√©parer features et target
        X, y = split_features_target(self.df_processed, target=TARGET_COLUMN)
        
        # Split train/test
        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(
            X, y,
            test_size=self.test_size,
            random_state=self.random_state,
            stratify=y
        )
        
        logger.info(f"Train set: {self.X_train.shape}")
        logger.info(f"Test set: {self.X_test.shape}")
        logger.info(f"Train labels distribution: {self.y_train.value_counts().to_dict()}")
        logger.info(f"Test labels distribution: {self.y_test.value_counts().to_dict()}")
        
        # Sauvegarder les datasets
        train_features_path = PROCESSED_DATA_DIR / "train_features.csv"
        train_labels_path = PROCESSED_DATA_DIR / "train_labels.csv"
        test_features_path = PROCESSED_DATA_DIR / "test_features.csv"
        test_labels_path = PROCESSED_DATA_DIR / "test_labels.csv"
        
        self.X_train.to_csv(train_features_path, index=False)
        self.y_train.to_csv(train_labels_path, index=False)
        self.X_test.to_csv(test_features_path, index=False)
        self.y_test.to_csv(test_labels_path, index=False)
        
        logger.success("Datasets train/test sauvegard√©s")

    def step3_train_model(self, use_grid_search: bool = False, cv_folds: int = None):
        """
        √âtape 3: Entra√Æner le mod√®le.
        
        Args:
            use_grid_search: Utiliser GridSearchCV
            cv_folds: Nombre de folds pour la validation crois√©e
        """
        logger.info("=" * 80)
        logger.info("√âTAPE 3: ENTRA√éNEMENT DU MOD√àLE")
        logger.info("=" * 80)
        
        cv_folds = cv_folds or DEFAULT_CV_FOLDS
        
        self.trainer = ModelTrainer(
            model_type=self.model_type,
            random_state=self.random_state
        )
        
        self.trainer.train(
            self.X_train,
            self.y_train,
            use_grid_search=use_grid_search,
            cv_folds=cv_folds
        )
        
        self.model = self.trainer.model
        
        # Sauvegarder le mod√®le
        model_path = MODELS_DIR / f"{self.model_type}_heart_disease.pkl"
        self.trainer.save_model(model_path)
        
        logger.success(f"Mod√®le entra√Æn√© et sauvegard√©: {model_path}")

    def step4_predict(self):
        """√âtape 4: Faire des pr√©dictions sur le test set."""
        logger.info("=" * 80)
        logger.info("√âTAPE 4: PR√âDICTIONS SUR LE TEST SET")
        logger.info("=" * 80)
        
        if self.model is None:
            raise RuntimeError("Le mod√®le n'est pas entra√Æn√©")
        
        # Pr√©dictions
        self.predictions = self.model.predict(self.X_test)
        logger.info(f"Pr√©dictions effectu√©es: {len(self.predictions)} √©chantillons")
        
        # Probabilit√©s
        if hasattr(self.model, "predict_proba"):
            self.probabilities = self.model.predict_proba(self.X_test)
            logger.info("Probabilit√©s calcul√©es")
        
        # Sauvegarder les pr√©dictions
        predictions_df = pd.DataFrame({
            "predictions": self.predictions
        })
        
        if self.probabilities is not None:
            for i in range(self.probabilities.shape[1]):
                predictions_df[f"proba_{i}"] = self.probabilities[:, i]
        
        predictions_path = PROCESSED_DATA_DIR / "test_predictions.csv"
        predictions_df.to_csv(predictions_path, index=False)
        logger.success(f"Pr√©dictions sauvegard√©es: {predictions_path}")

    def step5_evaluate(self):
        """√âtape 5: √âvaluer les performances du mod√®le."""
        logger.info("=" * 80)
        logger.info("√âTAPE 5: √âVALUATION DU MOD√àLE")
        logger.info("=" * 80)
        
        evaluator = ModelEvaluator(task_type="classification")
        
        self.metrics = evaluator.evaluate_classification(
            y_true=self.y_test.values,
            y_pred=self.predictions,
            y_proba=self.probabilities
        )
        
        evaluator.print_metrics()
        
        # Sauvegarder les m√©triques
        metrics_path = REPORTS_DIR / f"{self.model_type}_evaluation_metrics.json"
        evaluator.save_metrics(metrics_path)
        
        logger.success(f"M√©triques sauvegard√©es: {metrics_path}")

    def run_complete_pipeline(
        self,
        use_grid_search: bool = False,
        cv_folds: int = None
    ) -> Dict[str, Any]:
        """
        Execute le pipeline complet.
        
        Args:
            use_grid_search: Utiliser GridSearchCV
            cv_folds: Nombre de folds pour la validation crois√©e
        
        Returns:
            Dictionnaire avec les r√©sultats
        """
        logger.info("üöÄ D√âMARRAGE DU PIPELINE COMPLET")
        logger.info("=" * 80)
        
        # √âtape 1: Pr√©traitement
        self.step1_load_and_preprocess()
        
        # √âtape 2: Split
        self.step2_split_data()
        
        # √âtape 3: Entra√Ænement
        self.step3_train_model(use_grid_search=use_grid_search, cv_folds=cv_folds)
        
        # √âtape 4: Pr√©diction
        self.step4_predict()
        
        # √âtape 5: √âvaluation
        self.step5_evaluate()
        
        logger.info("=" * 80)
        logger.success("‚úÖ PIPELINE COMPLET TERMIN√â AVEC SUCC√àS!")
        logger.info("=" * 80)
        
        # R√©sum√©
        results = {
            "model_type": self.model_type,
            "train_size": len(self.X_train),
            "test_size": len(self.X_test),
            "metrics": self.metrics,
            "best_params": self.trainer.best_params if self.trainer else None
        }
        
        return results


@app.command()
def main(
    raw_data_path: Path = RAW_DATA_DIR / "heart_disease_dataset.csv",
    model_type: str = None,
    test_size: float = None,
    use_grid_search: bool = False,
    cv_folds: int = None,
    random_state: int = None,
):
    """
    Execute le pipeline complet de bout en bout.
    
    Args:
        raw_data_path: Chemin vers les donn√©es brutes
        model_type: Type de mod√®le (None = utilise DEFAULT_MODEL_TYPE)
        test_size: Proportion des donn√©es pour le test (None = utilise DEFAULT_TEST_SIZE)
        use_grid_search: Utiliser GridSearchCV pour optimiser les hyperparam√®tres
        cv_folds: Nombre de folds pour la validation crois√©e (None = utilise DEFAULT_CV_FOLDS)
        random_state: Graine al√©atoire (None = utilise DEFAULT_RANDOM_STATE)
    """
    pipeline = CompletePipeline(
        raw_data_path=raw_data_path,
        model_type=model_type,
        test_size=test_size,
        random_state=random_state
    )
    
    results = pipeline.run_complete_pipeline(
        use_grid_search=use_grid_search,
        cv_folds=cv_folds
    )
    
    # Afficher le r√©sum√© final
    logger.info("\n" + "=" * 80)
    logger.info("üìä R√âSUM√â DES R√âSULTATS")
    logger.info("=" * 80)
    logger.info(f"Mod√®le: {results['model_type']}")
    logger.info(f"Train size: {results['train_size']}")
    logger.info(f"Test size: {results['test_size']}")
    logger.info(f"Accuracy: {results['metrics']['accuracy']:.4f}")
    logger.info(f"F1 Score: {results['metrics']['f1_score']:.4f}")
    
    if results['best_params']:
        logger.info(f"Meilleurs param√®tres: {results['best_params']}")
    
    typer.echo("\n‚úÖ Pipeline termin√© avec succ√®s!")


if __name__ == "__main__":
    app()


# Exemples d'utilisation:
# 
# Pipeline basique avec Random Forest:
#   python -m corai.pipeline_complete
#
# Avec Gradient Boosting:
#   python -m corai.pipeline_complete --model-type gradient_boosting
#
# Avec optimisation d'hyperparam√®tres:
#   python -m corai.pipeline_complete --use-grid-search
#
# Tous les param√®tres:
#   python -m corai.pipeline_complete --model-type gradient_boosting --use-grid-search --test-size 0.25
